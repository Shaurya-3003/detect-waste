{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is partially based on this https://github.com/pedropro/TACO/blob/master/demo.ipynb and \n",
    "https://github.com/pedropro/TACO/blob/master/detector/detector.ipynb and\n",
    "https://www.kaggle.com/kneroma/clean-planet-trash-detection-dataset from the original **taco** project and kaggle.\n",
    "\n",
    "Updated to detectwaste by:\n",
    "* Agnieszka Mikołajczyk\n",
    "* Katarzyna Łangowska\n",
    "* Maria Ferlin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  EDA \n",
    "## TACO and detect-waste\n",
    "\n",
    "This notebook contains several independent scripts that show how to load and visualize the dataset stats and annotated images:\n",
    "- Section 1 shows the dataset stats\n",
    "- Section 2 shows the class hierarchical structure: super classes and classes\n",
    "- Section 3 shows TACO images along with their segmentation masks\n",
    "\n",
    "But first we need to load the annotations and some python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycocotools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13512/1266665951.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExifTags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpycocotools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPolygon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRectangle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPatchCollection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycocotools'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "from PIL import Image, ExifTags\n",
    "from pycocotools.coco import COCO\n",
    "from matplotlib.patches import Polygon, Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "import colorsys\n",
    "import random\n",
    "import pylab\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "module_path = str(Path.cwd().parents[0] / \"src\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "dataset_path = '/dih4/dih4_2/wimlds/TACO-master/data'\n",
    "anns_file_path = dataset_path + '/' + 'annotations.json'\n",
    "epinote_dataset_path = '/dih4/dih4_2/wimlds/data/not-annotated'\n",
    "epinote_anns_file_path = '/dih4/dih4_2/wimlds/data/annotations_epi.json'\n",
    "# Read annotations\n",
    "with open(anns_file_path, 'r') as f:\n",
    "    dataset = json.loads(f.read())\n",
    "with open(epinote_anns_file_path, 'r') as f:\n",
    "    epinote_dataset = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = dataset['categories']\n",
    "anns = dataset['annotations']\n",
    "imgs = dataset['images']\n",
    "nr_cats = len(categories)\n",
    "nr_annotations = len(anns)\n",
    "nr_images = len(imgs)\n",
    "\n",
    "# Load categories and super categories\n",
    "cat_names = []\n",
    "super_cat_names = []\n",
    "super_cat_ids = {}\n",
    "super_cat_last_name = ''\n",
    "nr_super_cats = 0\n",
    "for cat_it in categories:\n",
    "    cat_names.append(cat_it['name'])\n",
    "    super_cat_name = cat_it['supercategory']\n",
    "    # Adding new supercat\n",
    "    if super_cat_name != super_cat_last_name:\n",
    "        super_cat_names.append(super_cat_name)\n",
    "        super_cat_ids[super_cat_name] = nr_super_cats\n",
    "        super_cat_last_name = super_cat_name\n",
    "        nr_super_cats += 1\n",
    "\n",
    "print('Number of super categories:', nr_super_cats)\n",
    "print('Number of categories:', nr_cats)\n",
    "print('Number of annotations:', nr_annotations)\n",
    "print('Number of images:', nr_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotations in COCO format\n",
    "bbox = (x, y, width, height)\n",
    "area = multi_poly.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anns_to_print = anns[0].pop('segmentation', None) # removing segmentation polygon for better clarity\n",
    "anns[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Dataset statistics\n",
    "### TACO categories\n",
    "\n",
    "This shows the number of annotations per category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count annotations\n",
    "cat_histogram = np.zeros(nr_cats,dtype=int)\n",
    "for ann in anns:\n",
    "    cat_histogram[ann['category_id']] += 1\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(5,15))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'Categories': cat_names, 'Number of annotations': cat_histogram})\n",
    "df = df.sort_values('Number of annotations', 0, False)\n",
    "\n",
    "# Plot the histogram\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.set(style=\"whitegrid\")\n",
    "plot_1 = sns.barplot(x=\"Number of annotations\", y=\"Categories\", data=df,\n",
    "            label=\"Total\", color=\"b\")\n",
    "\n",
    "# fig = plot_1.get_figure()\n",
    "# fig.savefig(\"output.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and this shows the number of annotations per super category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ids_2_supercat_ids = {}\n",
    "for cat in categories:\n",
    "    cat_ids_2_supercat_ids[cat['id']] = super_cat_ids[cat['supercategory']]\n",
    "\n",
    "# Count annotations\n",
    "super_cat_histogram = np.zeros(nr_super_cats,dtype=int)\n",
    "for ann in anns:\n",
    "    cat_id = ann['category_id']\n",
    "    super_cat_histogram[cat_ids_2_supercat_ids[cat_id]] +=1\n",
    "    \n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(5,10))\n",
    "\n",
    "# Convert to DataFrame\n",
    "d ={'Super categories': super_cat_names, 'Number of annotations': super_cat_histogram}\n",
    "df = pd.DataFrame(d)\n",
    "df = df.sort_values('Number of annotations', 0, False)\n",
    "\n",
    "# sns.set_color_codes(\"pastel\")\n",
    "# sns.set(style=\"whitegrid\")\n",
    "plot_1 = sns.barplot(x=\"Number of annotations\", y=\"Super categories\", data=df,\n",
    "            label=\"Total\", color=\"b\")\n",
    "#plot_1.set_title('Annotations per super category',fontsize=20)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detect-waste categories\n",
    "\n",
    "This shows the number of annotations per category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert taco label to detect-waste labels\n",
    "# based on polish recykling standards\n",
    "# by Katrzyna łagocka\n",
    "\n",
    "\n",
    "def taco_to_detectwaste(label):\n",
    "    glass = ['Glass bottle','Broken glass','Glass jar']\n",
    "    metals_and_plastics = ['Aluminium foil', \"Clear plastic bottle\",\"Other plastic bottle\",\n",
    "                         \"Plastic bottle cap\",\"Metal bottle cap\",\"Aerosol\",\"Drink can\",\n",
    "                         \"Food can\",\"Drink carton\",\"Disposable plastic cup\",\"Other plastic cup\",\n",
    "                         \"Plastic lid\",\"Metal lid\",\"Single-use carrier bag\",\"Polypropylene bag\",\n",
    "                         \"Plastic Film\",\"Six pack rings\",\"Spread tub\",\"Tupperware\",\n",
    "                         \"Disposable food container\",\"Other plastic container\",\n",
    "                         \"Plastic glooves\",\"Plastic utensils\",\"Pop tab\",\"Scrap metal\",\n",
    "                         \"Plastic straw\",\"Other plastic\", \"Plastic film\", \"Food Can\"]\n",
    "    \n",
    "    non_recyclable = [\"Aluminium blister pack\",\"Carded blister pack\",\n",
    "                    \"Meal carton\",\"Pizza box\",\"Cigarette\",\"Paper cup\",\n",
    "                    \"Meal carton\",\"Foam cup\",\"Glass cup\",\"Wrapping paper\",\n",
    "                    \"Magazine paper\",\"Garbage bag\",\"Plastified paper bag\",\n",
    "                    \"Crisp packet\",\"Other plastic wrapper\",\"Foam food container\",\n",
    "                    \"Rope\",\"Shoe\",\"Squeezable tube\",\"Paper straw\",\"Styrofoam piece\", \"Rope & strings\", \"Tissues\"]\n",
    "    \n",
    "    other = [\"Battery\"]\n",
    "    paper = [\"Corrugated carton\",\"Egg carton\",\"Toilet tube\",\"Other carton\", \"Normal paper\", \"Paper bag\"]\n",
    "    bio = [\"Food waste\"]\n",
    "    unknown = [\"Unlabeled litter\"]\n",
    "\n",
    "    if (label in glass):\n",
    "            label=\"glass\"\n",
    "    elif (label in metals_and_plastics):\n",
    "            label=\"metals_and_plastics\"\n",
    "    elif(label in non_recyclable):\n",
    "            label=\"non-recyclable\"\n",
    "    elif(label in other):\n",
    "            label=\"other\"\n",
    "    elif (label in paper):\n",
    "            label=\"paper\"\n",
    "    elif(label in bio):\n",
    "            label=\"bio\"\n",
    "    elif(label in unknown):\n",
    "            label=\"unknown\"\n",
    "    else:\n",
    "        print(label, \"is non-taco label\")\n",
    "        label = \"unknown\"\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all taco anns to detect-waste anns\n",
    "# let's change supercategory to detectwaste\n",
    "detectwaste_categories = dataset['categories']\n",
    "for ann in anns:\n",
    "    cat_id = ann['category_id']\n",
    "    cat_taco = categories[cat_id]['name']\n",
    "    detectwaste_categories[cat_id]['supercategory'] = taco_to_detectwaste(cat_taco)\n",
    "# As there is no representation of \"Plastified paper bag\" in annotated data, change of this supercategory was done manually.\n",
    "detectwaste_categories[35]['supercategory'] = taco_to_detectwaste(\"Plastified paper bag\")\n",
    "detectwaste_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_categories = epinote_dataset['categories']\n",
    "epi_anns = epinote_dataset['annotations']\n",
    "epi_imgs = epinote_dataset['images']\n",
    "\n",
    "def epi_to_detectwaste(epi_id):\n",
    "    new_id = 6\n",
    "\n",
    "    if epi_id == 5:\n",
    "        new_id = 0\n",
    "    if epi_id == 6:\n",
    "        new_id = 1\n",
    "    if epi_id == 3:\n",
    "        new_id = 2\n",
    "    if epi_id == 2:\n",
    "        new_id = 3\n",
    "    if epi_id == 1:\n",
    "        new_id = 4\n",
    "    if epi_id == 7:\n",
    "        new_id = 5\n",
    "    if epi_id == 4:\n",
    "        new_id = 6\n",
    "\n",
    "    return new_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in epi_categories:\n",
    "    new_id = epi_to_detectwaste(cat['id'])\n",
    "    cat['id'] = new_id\n",
    "for ann in epi_anns:\n",
    "    new_cat = epi_to_detectwaste(ann['category_id'])\n",
    "    ann['category_id'] = new_cat\n",
    "epi_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate new ids for ploting histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectwaste_ids = {}\n",
    "detectwaste_cat_names = []\n",
    "cat_id = 0\n",
    "for cat in detectwaste_categories:\n",
    "    if cat['supercategory'] not in detectwaste_ids:\n",
    "        detectwaste_cat_names.append(cat['supercategory'])\n",
    "        detectwaste_ids[cat['supercategory']] = cat_id\n",
    "        cat_id += 1\n",
    "        \n",
    "print(detectwaste_ids)\n",
    "print(detectwaste_cat_names)\n",
    "\n",
    "taco_to_detectwaste_ids = {}\n",
    "for i, cat in enumerate(detectwaste_categories):\n",
    "#     if cat['id'] not in taco_to_detectwaste_ids:\n",
    "#         taco_to_detectwaste_ids[cat['id']] = 0\n",
    "    taco_to_detectwaste_ids[cat['id']] = detectwaste_ids[cat['supercategory']]\n",
    "    \n",
    "# print(taco_to_detectwaste_ids)\n",
    "\n",
    "colors_recykling = ['yellow', 'gray', 'gray', 'green', 'blue', 'brown', 'pink']\n",
    "\n",
    "anns_detectwaste = anns.copy()\n",
    "for i, ann in enumerate(anns):\n",
    "    #print(ann['category_id'])\n",
    "    anns_detectwaste[i]['category_id'] = taco_to_detectwaste_ids[ann['category_id']]\n",
    "    anns_detectwaste[i].pop('segmentation', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count annotations\n",
    "detectwaste_cat_histogram = np.zeros(len(detectwaste_cat_names),dtype=int)\n",
    "\n",
    "for ann in anns_detectwaste:\n",
    "    cat_id = ann['category_id']\n",
    "    detectwaste_cat_histogram[cat_id] +=1\n",
    "    \n",
    "for ann in epi_anns:\n",
    "    cat_id = ann['category_id']\n",
    "    detectwaste_cat_histogram[cat_id] +=1\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(5,10))\n",
    "\n",
    "# Convert to DataFrame\n",
    "d ={'Super categories': detectwaste_cat_names, 'Number of annotations': detectwaste_cat_histogram}\n",
    "df = pd.DataFrame(d)\n",
    "df = df.sort_values('Number of annotations', 0, False)\n",
    "\n",
    "\n",
    "sns.set_palette(sns.color_palette(colors_recykling))\n",
    "plot_1 = sns.barplot(x=\"Number of annotations\", y=\"Super categories\", data=df,\n",
    "            label=\"Total\")\n",
    "plot_1.set_title('Annotations per detectwaste category',fontsize=20)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2  Background stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scene cat names\n",
    "scene_cats = dataset['scene_categories']\n",
    "scene_name = []\n",
    "pylab.rcParams['figure.figsize'] = (6,6)\n",
    "\n",
    "for scene_cat in scene_cats:\n",
    "    scene_name.append(scene_cat['name'])\n",
    "\n",
    "nr_scenes = len(scene_cats)\n",
    "scene_cat_histogram = np.zeros(nr_scenes,dtype=int)\n",
    "\n",
    "for scene_ann in dataset['scene_annotations']:    \n",
    "    scene_ann_ids = scene_ann['background_ids']\n",
    "    for scene_ann_id in scene_ann_ids:\n",
    "        if scene_ann_id<len(scene_cats):\n",
    "            scene_cat_histogram[scene_ann_id]+=1\n",
    "\n",
    "# Plot\n",
    "colors = ['white','black','gray', 'gold', 'red','green','lightskyblue']\n",
    "plt.pie(scene_cat_histogram, labels=scene_name, colors = colors,\n",
    "      shadow=False, startangle=-120)\n",
    " \n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Annotated Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, to select and show the dataset images with the respective masks, we make use of the COCO API.\n",
    "The script below shows how to load and visualize an image with all its annotations.\n",
    "\n",
    "Unfortunately, several python libraries do not take into account the EXIF orientation tag, thus we have to explicitly rotate the images. Alternatively you can use instead OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script below shows how to filter images by either category or supercategory.\n",
    "\n",
    "Go ahead and try different (super)categories searches by changing the `category_name`.\n",
    "Note that small objects may be hard to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_detectwaste_color(ann, taco_to_detectwaste_ids, colors_recykling):\n",
    "    color_id = taco_to_detectwaste_ids[ann['category_id']]\n",
    "    color = colors_recykling[color_id]\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User settings\n",
    "image_filepath = 'batch_11/000028.jpg'\n",
    "pylab.rcParams['figure.figsize'] = (28,28)\n",
    "####################\n",
    "imgs = dataset['images']\n",
    "\n",
    "# Obtain Exif orientation tag code\n",
    "for orientation in ExifTags.TAGS.keys():\n",
    "    if ExifTags.TAGS[orientation] == 'Orientation':\n",
    "        break\n",
    "\n",
    "# Loads dataset as a coco object\n",
    "coco = COCO(anns_file_path)\n",
    "\n",
    "# Find image id\n",
    "img_id = -1\n",
    "for img in imgs:\n",
    "    if img['file_name'] == image_filepath:\n",
    "        img_id = img['id']\n",
    "        break\n",
    "\n",
    "# Show image and corresponding annotations\n",
    "if img_id == -1:\n",
    "    print('Incorrect file name')\n",
    "else:\n",
    "\n",
    "    # Load image\n",
    "    print(image_filepath)\n",
    "    I = Image.open(dataset_path + '/' + image_filepath)\n",
    "\n",
    "    # Load and process image metadata\n",
    "    if I._getexif():\n",
    "        exif = dict(I._getexif().items())\n",
    "        # Rotate portrait and upside down images if necessary\n",
    "        if orientation in exif:\n",
    "            if exif[orientation] == 3:\n",
    "                I = I.rotate(180,expand=True)\n",
    "            if exif[orientation] == 6:\n",
    "                I = I.rotate(270,expand=True)\n",
    "            if exif[orientation] == 8:\n",
    "                I = I.rotate(90,expand=True)\n",
    "\n",
    "    # Show image\n",
    "    fig,ax = plt.subplots(1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(I)\n",
    "\n",
    "    # Load mask ids\n",
    "    annIds = coco.getAnnIds(imgIds=img_id, catIds=[], iscrowd=None)\n",
    "    anns_sel = coco.loadAnns(annIds)\n",
    "\n",
    "    # Show annotations\n",
    "    for ann in anns_sel:\n",
    "        color = extract_detectwaste_color(ann, taco_to_detectwaste_ids, colors_recykling)\n",
    "        for seg in ann['segmentation']:\n",
    "            poly = Polygon(np.array(seg).reshape((int(len(seg)/2), 2)))\n",
    "            p = PatchCollection([poly], facecolor=color, edgecolors=color,linewidths=0, alpha=0.4)\n",
    "            ax.add_collection(p)\n",
    "            p = PatchCollection([poly], facecolor='none', edgecolors=color, linewidths=2)\n",
    "            ax.add_collection(p)\n",
    "        [x, y, w, h] = ann['bbox']\n",
    "        rect = Rectangle((x,y),w,h,linewidth=2,edgecolor=color,\n",
    "                         facecolor='none', alpha=0.7, linestyle = '--')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_to_show = ['Bottle', 'Shoe', 'Food waste']\n",
    "nr_img_2_display = 1\n",
    "pylab.rcParams['figure.figsize'] = (14,14)\n",
    "\n",
    "for category_name in categories_to_show: #  --- Insert the name of one of the categories or super-categories above\n",
    "\n",
    "    # Obtain Exif orientation tag code\n",
    "    for orientation in ExifTags.TAGS.keys():\n",
    "        if ExifTags.TAGS[orientation] == 'Orientation':\n",
    "            break\n",
    "\n",
    "    # Loads dataset as a coco object\n",
    "    coco = COCO(anns_file_path)\n",
    "\n",
    "    # Get image ids\n",
    "    imgIds = []\n",
    "    catIds = coco.getCatIds(catNms=[category_name])\n",
    "    if catIds:\n",
    "        # Get all images containing an instance of the chosen category\n",
    "        imgIds = coco.getImgIds(catIds=catIds)\n",
    "    else:\n",
    "        # Get all images containing an instance of the chosen super category\n",
    "        catIds = coco.getCatIds(supNms=[category_name])\n",
    "        for catId in catIds:\n",
    "            imgIds += (coco.getImgIds(catIds=catId))\n",
    "        imgIds = list(set(imgIds))\n",
    "\n",
    "    nr_images_found = len(imgIds) \n",
    "    print('Number of images found: ',nr_images_found)\n",
    "\n",
    "    # Select N random images\n",
    "    random.shuffle(imgIds)\n",
    "    imgs = coco.loadImgs(imgIds[0:min(nr_img_2_display,nr_images_found)])\n",
    "\n",
    "    for img in imgs:\n",
    "        image_path = dataset_path + '/' + img['file_name']\n",
    "        # Load image\n",
    "        I = Image.open(image_path)\n",
    "\n",
    "        # Load and process image metadata\n",
    "        if I._getexif():\n",
    "            exif = dict(I._getexif().items())\n",
    "            # Rotate portrait and upside down images if necessary\n",
    "            if orientation in exif:\n",
    "                if exif[orientation] == 3:\n",
    "                    I = I.rotate(180,expand=True)\n",
    "                if exif[orientation] == 6:\n",
    "                    I = I.rotate(270,expand=True)\n",
    "                if exif[orientation] == 8:\n",
    "                    I = I.rotate(90,expand=True)\n",
    "\n",
    "        # Show image\n",
    "        fig,ax = plt.subplots(1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(I)\n",
    "\n",
    "        # Load mask ids\n",
    "        annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\n",
    "        anns_sel = coco.loadAnns(annIds)\n",
    "\n",
    "        # Show annotations\n",
    "        for ann in anns_sel:\n",
    "            color = extract_detectwaste_color(ann, taco_to_detectwaste_ids, colors_recykling)\n",
    "            for seg in ann['segmentation']:\n",
    "                poly = Polygon(np.array(seg).reshape((int(len(seg)/2), 2)))\n",
    "                p = PatchCollection([poly], facecolor=color, edgecolors=color,linewidths=0, alpha=0.4)\n",
    "                ax.add_collection(p)\n",
    "                p = PatchCollection([poly], facecolor='none', edgecolors=color, linewidths=2)\n",
    "                ax.add_collection(p)\n",
    "            [x, y, w, h] = ann['bbox']\n",
    "            rect = Rectangle((x,y),w,h,linewidth=2,edgecolor=color,\n",
    "                             facecolor='none', alpha=0.7, linestyle = '--')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. bbox statistics\n",
    "* average bbox size per category\n",
    "* average area size per category\n",
    "* average number of bbox per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anns_detectwaste[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_stats(anns, calc = 'mean', verbose = 1):\n",
    "    picsw = [pic['bbox'][2] for pic in anns]\n",
    "    picsh = [pic['bbox'][3] for pic in anns]\n",
    "    bbox_size = [w * h for w, h, in zip(picsw,picsh)]\n",
    "    if calc == 'mean':\n",
    "        return np.mean(bbox_size)\n",
    "    if calc == 'median':\n",
    "        return np.median(bbox_size)\n",
    "\n",
    "def area_stats(anns, calc = 'mean', verbose = 1):\n",
    "    picsw = [pic['area'] for pic in anns]\n",
    "    picsh = [pic['area'] for pic in anns]\n",
    "    area_size = [w * h for w, h, in zip(picsw,picsh)]\n",
    "    if calc == 'mean':\n",
    "        return np.mean(area_size)\n",
    "    if calc == 'median':\n",
    "        return np.median(area_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = (12,6)\n",
    "\n",
    "mean_bbox = []\n",
    "median_bbox = []\n",
    "for cat_nr, cat in enumerate(detectwaste_cat_names):\n",
    "    temp_anns = [ann for ann in anns_detectwaste if(ann['category_id'] == cat_nr)]\n",
    "    mean_bbox.append(bbox_stats(temp_anns,)) \n",
    "    median_bbox.append(bbox_stats(temp_anns,'median'))\n",
    "mean_bbox[-1] =0\n",
    "median_bbox[-1] =0\n",
    "\n",
    "# append stats for all for comparison\n",
    "temp_detectwaste_cat_names = detectwaste_cat_names.copy()\n",
    "temp_detectwaste_cat_names.append('all')\n",
    "mean_bbox.append(bbox_stats(anns_detectwaste)) \n",
    "median_bbox.append(bbox_stats(anns_detectwaste,'median'))\n",
    "\n",
    "colors = []\n",
    "colors = colors_recykling.copy()\n",
    "colors.append('red')\n",
    "plt.bar(temp_detectwaste_cat_names,mean_bbox, color=colors)\n",
    "plt.title('Mean size of bbox')\n",
    "plt.show()\n",
    "\n",
    "plt.bar(temp_detectwaste_cat_names,median_bbox, color=colors)\n",
    "plt.title('Median size of bbox')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_area = []\n",
    "median_area = []\n",
    "for cat_nr, cat in enumerate(detectwaste_cat_names):\n",
    "    temp_anns = [ann for ann in anns_detectwaste if(ann['category_id'] == cat_nr)]\n",
    "    mean_area.append(area_stats(temp_anns,)) \n",
    "    median_area.append(area_stats(temp_anns,'median'))\n",
    "\n",
    "mean_area[-1] = 0\n",
    "median_area[-1] = 0\n",
    "mean_area.append(area_stats(anns_detectwaste)) \n",
    "median_area.append(area_stats(anns_detectwaste,'median'))\n",
    "print(temp_detectwaste_cat_names)\n",
    "\n",
    "plt.bar(temp_detectwaste_cat_names,mean_area, color=colors)\n",
    "plt.title('Mean size of area')\n",
    "plt.show()\n",
    "\n",
    "plt.bar(temp_detectwaste_cat_names,median_area, color=colors)\n",
    "plt.title('Median size of area')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of bboxes per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_bbox_per_image(anns):\n",
    "    temo_im_ids = ([ann['image_id'] for ann in anns])\n",
    "    temp_im_ids = Counter(temo_im_ids)\n",
    "    list_of_duplicates = [temp_im_ids[i] for i,im_id in enumerate(temp_im_ids)]\n",
    "    list_of_duplicates = list(filter(lambda duplicate: duplicate != 0, list_of_duplicates))\n",
    "    return np.mean(list_of_duplicates)\n",
    "def no_bbox_summary(anns):\n",
    "    temo_im_ids = ([ann['image_id'] for ann in anns])\n",
    "    temp_im_ids = Counter(temo_im_ids)\n",
    "    list_of_duplicates = [temp_im_ids[i] for i,im_id in enumerate(temp_im_ids)]\n",
    "    list_of_duplicates = list(filter(lambda duplicate: duplicate != 0, list_of_duplicates))\n",
    "    print('Maximum bboxes: ',np.max(list_of_duplicates))\n",
    "    print('Mean number of bboxes: ',np.mean(list_of_duplicates))\n",
    "    print('Median number of bboxes: ',np.median(list_of_duplicates))\n",
    "\n",
    "\n",
    "print('all:',no_bbox_per_image(anns_detectwaste))\n",
    "for cat_nr, cat in enumerate(detectwaste_cat_names):\n",
    "    try:\n",
    "        temp_anns = [ann for ann in anns_detectwaste if(ann['category_id'] == cat_nr)]\n",
    "        print('\\n', cat)\n",
    "        no_bbox_summary(temp_anns)\n",
    "    except:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of images per image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing image shapes (resolutions)\n",
    "widths = []\n",
    "heights = []\n",
    "shape_freqs = []\n",
    "img_shapes_keys = {}\n",
    "for img in dataset['images']:\n",
    "    key = str(img['width'])+'-'+str(img['height'])\n",
    "    if key in img_shapes_keys:\n",
    "        shape_id = img_shapes_keys[key]\n",
    "        shape_freqs[shape_id] += 1\n",
    "    else:\n",
    "        img_shapes_keys[key] = len(widths)\n",
    "        widths.append(img['width'])\n",
    "        heights.append(img['height'])\n",
    "        shape_freqs.append(1)\n",
    "for img in epinote_dataset['images']:\n",
    "    key = str(img['width'])+'-'+str(img['height'])\n",
    "    if key in img_shapes_keys:\n",
    "        shape_id = img_shapes_keys[key]\n",
    "        shape_freqs[shape_id] += 1\n",
    "    else:\n",
    "        img_shapes_keys[key] = len(widths)\n",
    "        widths.append(img['width'])\n",
    "        heights.append(img['height'])\n",
    "        shape_freqs.append(1)\n",
    "\n",
    "d ={'Image width (px)': widths, 'Image height (px)': heights, '# images': shape_freqs}\n",
    "df = pd.DataFrame(d)\n",
    "cmap = sns.cubehelix_palette(dark=.1, light=.6, as_cmap=True)\n",
    "plot = sns.scatterplot(x=\"Image width (px)\", y=\"Image height (px)\", size='# images', hue=\"# images\", palette = cmap,data=df)\n",
    "plt.xlabel('Image width (px)', fontsize=15)\n",
    "plt.ylabel('Image height (px)', fontsize=15)\n",
    "plot = plot.set_title('Number of images per image shape',fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placement of central point of the bbox in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_x = []\n",
    "center_y = []\n",
    "for i in range(0, len(anns_detectwaste)):\n",
    "    for j in range (0, len(dataset['images'])):\n",
    "        if dataset['images'][j]['id'] == anns_detectwaste[i]['image_id']:\n",
    "            \n",
    "            center_x.append((anns_detectwaste[i]['bbox'][0]+anns_detectwaste[i]['bbox'][2]/2)/dataset['images'][j]['width'])\n",
    "            center_y.append((anns_detectwaste[i]['bbox'][1]+anns_detectwaste[i]['bbox'][3]/2)/dataset['images'][j]['height'])\n",
    "for i in range(0, len(epi_anns)):\n",
    "    for j in range (0, len(epinote_dataset['images'])):\n",
    "        if epinote_dataset['images'][j]['id'] == epi_anns[i]['image_id']:\n",
    "            \n",
    "            center_x.append((epi_anns[i]['bbox'][0]+epi_anns[i]['bbox'][2]/2)/epinote_dataset['images'][j]['width'])\n",
    "            center_y.append((epi_anns[i]['bbox'][1]+epi_anns[i]['bbox'][3]/2)/epinote_dataset['images'][j]['height'])\n",
    "plt.figure(figsize=(30,15))\n",
    "plt.plot(center_x, center_y, 'bo')\n",
    "plt.title('Placement of central point of the bbox in the image', fontsize=30)\n",
    "plt.xlabel('Bbox x coordinate', fontsize=30)\n",
    "plt.ylabel('Bbox y coordinate', fontsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of annotations per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_annotation_per_image = []\n",
    "annotations_per_image = []\n",
    "for img in dataset['images']:\n",
    "    annotations_per_image = []\n",
    "    for i in range(0, len(anns_detectwaste)):\n",
    "        if img['id'] == anns_detectwaste[i]['image_id']:\n",
    "            annotations_per_image.append(anns_detectwaste[i]['id'])\n",
    "    nr_annotation_per_image.append(len(annotations_per_image))\n",
    "for img in epinote_dataset['images']:\n",
    "    annotations_per_image = []\n",
    "    for i in range(0, len(epi_anns)):\n",
    "        if img['id'] == epi_anns[i]['image_id']:\n",
    "            annotations_per_image.append(epi_anns[i]['id'])\n",
    "    nr_annotation_per_image.append(len(annotations_per_image)) \n",
    "plt.figure(figsize=(30,15))\n",
    "ax = sns.distplot(nr_annotation_per_image,kde=False,bins=100, color='g')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Mean number of annotations per image', fontsize=30)\n",
    "plt.xlabel('Number of annotations per image', fontsize=30)\n",
    "plt.ylabel('Image Count', fontsize=30)\n",
    "\n",
    "print('Mean number of annotations per image:',np.mean(nr_annotation_per_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bbox size - absolute and relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_widths = []\n",
    "bbox_heights = []\n",
    "obj_areas_sqrt = []\n",
    "obj_areas_sqrt_fraction = []\n",
    "bbox_aspect_ratio = []\n",
    "max_image_dim = 1024\n",
    "\n",
    "for ann in anns_detectwaste:\n",
    "    \n",
    "    imgs = dataset['images']\n",
    "    \n",
    "    resize_scale = max_image_dim/max(imgs[0]['width'], imgs[0]['height'])\n",
    "    # Uncomment this to work on original image size\n",
    "#     resize_scale = 1\n",
    "    \n",
    "    bbox_widths.append(ann['bbox'][2]*resize_scale)\n",
    "    bbox_heights.append(ann['bbox'][3]*resize_scale)\n",
    "    obj_area = ann['bbox'][2]*ann['bbox'][3]*resize_scale**2 # ann['area']\n",
    "    obj_areas_sqrt.append(np.sqrt(obj_area))\n",
    "        \n",
    "    img_area = imgs[0]['width']*imgs[0]['height']*resize_scale**2\n",
    "    obj_areas_sqrt_fraction.append(np.sqrt(obj_area/img_area))\n",
    "    \n",
    "for ann in epi_anns:\n",
    "    \n",
    "    imgs = dataset['images']\n",
    "    \n",
    "    resize_scale = max_image_dim/max(imgs[0]['width'], imgs[0]['height'])\n",
    "    # Uncomment this to work on original image size\n",
    "#     resize_scale = 1\n",
    "    \n",
    "    bbox_widths.append(ann['bbox'][2]*resize_scale)\n",
    "    bbox_heights.append(ann['bbox'][3]*resize_scale)\n",
    "    obj_area = ann['bbox'][2]*ann['bbox'][3]*resize_scale**2 # ann['area']\n",
    "    obj_areas_sqrt.append(np.sqrt(obj_area))\n",
    "        \n",
    "    img_area = imgs[0]['width']*imgs[0]['height']*resize_scale**2\n",
    "    obj_areas_sqrt_fraction.append(np.sqrt(obj_area/img_area))\n",
    "    \n",
    "print('According to MS COCO Evaluation. This dataset has:')\n",
    "print(np.sum(np.array(obj_areas_sqrt)<32), 'small objects (area<32*32 px)')\n",
    "print(np.sum(np.array(obj_areas_sqrt)<64), 'medium objects (area<96*96 px)')\n",
    "print(np.sum(np.array(obj_areas_sqrt)<96), 'large objects (area>96*96 px)')\n",
    "    \n",
    "# d ={'Bbox width (px)': bbox_widths, 'Bbox height (px)': bbox_heights, 'area': seg_areas}\n",
    "# df = pd.DataFrame(d)\n",
    "\n",
    "plt.figure(figsize=(30,15))\n",
    "ax = sns.distplot(obj_areas_sqrt_fraction,kde=False, bins=200, color='g')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Number of annotations per relative bbox size', fontsize=30)\n",
    "plt.xlabel(r'Annotation relative size as $\\sqrt{ Bbox\\_area \\ /  \\ Image\\_area}$', fontsize=30)\n",
    "plt.ylabel('Number of annotations', fontsize=30)\n",
    "\n",
    "plt.figure(figsize=(20,7))\n",
    "ax = sns.distplot(np.maximum(np.array(bbox_widths),np.array(bbox_heights)),kde=False, bins=200, color='g')\n",
    "ax = ax.set(xlabel='Maximum bbox dimension', ylabel='Number of annotations')\n",
    "\n",
    "import colorsys\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "\n",
    "# Plotting bbox dims\n",
    "d ={'BBox width (px)': bbox_widths, 'BBox height (px)': bbox_heights}\n",
    "df = pd.DataFrame(d)\n",
    "cmap = sns.cubehelix_palette(dark=.1, light=.6, as_cmap=True)\n",
    "ax = sns.scatterplot(x=\"BBox width (px)\", y=\"BBox height (px)\", palette = cmap,data=df)\n",
    "\n",
    "print('Number of bboxes smaller than 1024:',np.sum(np.array(bbox_widths)<1024))\n",
    "print('Number of bboxes larger than 1024:',np.sum(np.array(bbox_widths)>1024))\n",
    "\n",
    "# anchors = [(32,32),(64,64),(128,128),(256,256),(512,512)]\n",
    "scales, ratios = np.meshgrid(np.array([16,32,64,128,256,512]), np.array([0.5,1,2]))\n",
    "scales = scales.flatten()\n",
    "ratios = ratios.flatten()\n",
    "# Enumerate heights and widths from scales and ratios\n",
    "anchor_heights = scales / np.sqrt(ratios)\n",
    "anchor_widths = scales * np.sqrt(ratios)\n",
    "\n",
    "IoUs = []\n",
    "for i in range(len(bbox_widths)):\n",
    "    bbox_area = bbox_widths[i]*bbox_heights[i]\n",
    "    IoU_max = 0.0\n",
    "    for j in range(len(anchor_heights)):\n",
    "        anchor_area = anchor_heights[j]*anchor_widths[j]\n",
    "        intersection_area = min(anchor_widths[j],bbox_widths[i])*min(anchor_heights[j], bbox_heights[i])\n",
    "        IoU = intersection_area / (bbox_area + anchor_area - intersection_area)\n",
    "        if IoU>0.5:\n",
    "            IoU_max = IoU\n",
    "    IoUs.append(IoU_max)\n",
    "    \n",
    "print('Number of missing annotations', np.sum(np.array(IoUs)==0.0))\n",
    "  \n",
    "# Plotting bbox dims\n",
    "d ={'BBox width (px)': bbox_widths, 'BBox height (px)': bbox_heights, 'IoU': IoUs}\n",
    "df = pd.DataFrame(d)\n",
    "cmap = sns.cubehelix_palette(dark=.1, light=.6, as_cmap=True)\n",
    "ax = sns.scatterplot(x=\"BBox width (px)\", y=\"BBox height (px)\", hue = 'IoU',data=df)\n",
    "plt.title('Bounding-boxes size', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 32.831672,
   "end_time": "2020-08-12T01:36:33.161401",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-12T01:36:00.329729",
   "version": "2.1.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "b471adbcd4fafad39254ed0fee3171f9ad1066b7d703de61b767fb33843ecfe8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
